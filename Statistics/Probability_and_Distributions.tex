
%\section{Probability and Distribution}
\section{General Probability Theory}

\subsection{Random Variables}
\begin{definition}\index{Probability Space}
A \textbf{probability space} $(\Omega,\mathfrak{R},\mathbb{P})$ is a triple of a set $\Omega$ and $\sigma$-additive measure $\mathbb{P}$ with domain $\mathfrak{R}$, a $\sigma$-algebra defined on $\Omega$, satisfying $\mathbb{P}(\Omega) = 1$ and $\mathbb{P}(\varnothing)=0$.
\end{definition}
A event can be represented as an element in $\Omega$. A type of events can be abstracted as a subset $A\in\Omega$. The measure $\mathbb{P}(A)$ is called the probability of event $A$ happens. If $\mathbb{P}(A)=1$, we say that $A$ will occurs almost surely.

\begin{definition}\index{Random variable}
A \textbf{random variable} $X$ on $(\Omega,\mathfrak{R},\mathbb{P})$ is a $\mathfrak{R}$-measurable function $X:\Omega\to\realR$. The $\mathfrak{R}$-measurable here means:
	\begin{equation}
		X^{-1}(B)=\{\omega:\omega\in\Omega, X(\omega)\in B\}\in\mathfrak{R},
	\end{equation}
where $B$ is any Borel subset of $\realR$.
\end{definition}
A random variables is a function encoding events into real numbers for mathematical modeling purpose. Furthermore, as a random variable is a mapping from $\Omega$ to $\realR$, it will natrually induce the following practical conceptation.

\begin{definition}
\index{Random variable!Distribution measure}
The \textbf{distribution measure} $\mu_X$ of $X$ is a pushforward measure induced by $X$ as $\mu_X(B)=X_*\mathbb{P}=\mathbb{P}\{X^{-1}(B)\}$, where $B$ is any Borel subset of $\realR$.
\end{definition}
The \textbf{Radon-Nikodym}'s theorem implies that there exists a non-negative function $f(x)$ bridged the distribution measure $\mu_X$ and the natural linear measure of $\realR$ as
\begin{equation}
\mu_X(B) = \int_B f(x)d x, \quad\forall B\in\realR,
\end{equation} 
where the $B$ is a Borel subset of $\realR$. This function $f(X)$ is called the \textbf{probability density function} (PDF). A \textbf{cumulative distribution function}(CDF) $F(x)$ is defined as $F(x)=\mathbb{P}\{X\le x\}$.
\index{Random variable!Probability distribution function}
\index{Random variable!Accumulative distribution function}
Assum $g$ is a measurable function and $g(x)f(x)$ is integrable, then
\begin{equation}
\int_{\realR} g(x)d\mu_X=\int_{X^{-1}(\realR)}(g\circ X)(\omega)d\mathbb{P}=\int_\realR g(x)f(x)dx.
\end{equation}
To simplify, we assume that $X^{-1}(\realR)=\Omega$ for any random variable defined on $(\Omega,\mathfrak{R},\mathbb{P})$. Furthermore, suppose $G(x)$ is a function of $X$, and $f(x)$ is PDF of $X$, then
\begin{equation}
\int_\Omega G[X(\omega)]d\mathbb{P} = \int_{\realR} G(x)f(x)dx,
\label{eq:expectation_representation}
\end{equation}
if $G(x)f(x)$ is integrable over $\realR$ respect to the natural linear measure.

\begin{definition}
\index{Random variable!Expectation}
If a random vairable $X$ is integrable, the \textbf{expectation} of $X$, denoted as $\mathbb{E}(X)$ is defined as
	\begin{equation}
	\mathbb{E}(X)=\int_{\Omega}X(\omega) d\mathbb{P}.
	\end{equation}
\end{definition}
Based on the Eq.\ref{eq:expectation_representation}, the expectation $\mathbb{E}(X)$ can be calculated from
\begin{equation*}
\mathbb{E}(X)=\int_\realR xf(x)dx.
\end{equation*}

\begin{definition}
\index{Random variable!Independence}
A $\sigma$-algebra generated by a random variable $X$, denoted as $\sigma(X)$ is the collection of subsets $X^{-1}(B)$ where $B$ is any Borel subset of $\realR$. Since $X$ is required to be $\mathfrak{R}$-measurable by definition, it follows $\sigma(X)\subseteq\mathfrak{R}$. Furthermore, suppose two $\sigma$-algebra $\mathfrak{G,H}\subseteq\mathfrak{R}$, we called them are \textbf{independent} with each other if
	\begin{equation}
	\mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B),\quad \forall A\in\mathfrak{G}, \forall B\in\mathfrak{H}.
	\label{eq:def_independence}
	\end{equation}
We say two random varialbes $X$ and $Y$ are independent if $\sigma(X)$ and $\sigma(Y)$ are independent, denoted as $X\ci Y$.
\end{definition}

\begin{definition}
\index{Random variable!Moment generating functions}
A \textbf{moment generating function} $M_X(t)$, $t\in\realR$ for a random varialbe $X$ is definted as $M_X(t)=\mathbb{E}e^{tX}$.
\end{definition}

\begin{theorem}
The following properties of moment generating functions are straight forward:
	\begin{enumerate}
	\item $\mathbb{E}(X^n)=M_X^{(n)}(0)$, $n$th derivative of $M_X(t)$.
	\item If $M_X(t)=M_Y(t)$, then $X=Y$.
	\end{enumerate}
\end{theorem}


\subsection{Joint Probabilities and Independence}
\begin{definition}
Given two random variables $X,Y$, the pair $(X,Y)$ forms a mapping $X\times Y:\Omega\to\realR^2$, the \textbf{joint probability measure} $\mu_{X,Y}$ is defined as a pushforward measure
\begin{equation}
\mu_{X,Y}(A\times B)=\mathbb{P}[(X\times Y)^{-1}(A\times B)], \quad \forall A\times B\in\mathfrak{B}(\realR^2),
\end{equation}
where $\mathfrak{B}(\realR^2)$ represent all the Borel subsets of $\realR^2$ and
\begin{equation}
(X\times Y)^{-1}(A\times B) = X^{-1}(A)\cap Y^{-1}(B),
\end{equation}
\end{definition}

\begin{theorem}
Suppose $X,Y$, then the following conditions are equivalent
\begin{enumerate}
	\item  $X\ci Y$;
	\item For the joint measure $\mu_{X,Y}(A\times B)=\mu_X(A)\mu_Y(B)$, $\forall A\times B\in\mathfrak{B}(\realR^2)$
	\item For the PDF $f_X(x)$, $f_Y(y)$ and $f_{X,Y}(x,y)$ or CDF $F_X(x)$, etc:
	\begin{equation}
	\begin{aligned}
	f_{X,Y}(a,b) &= f_X(a)f_Y(b),\quad \forall\text{a.e.} (a,b)\in\realR^2,\\
	F_{X,Y}(a,b) &= F_X(a)F_Y(b),\quad \forall (a,b)\in\realR^2;
	\end{aligned}
	\end{equation}
	\item For the joint moment generating function:
	\begin{equation}
	\mathbb{E}e^{uX+vY}=\mathbb{E}e^{uX}\mathbb{E}e^{vY};
	\end{equation}
\end{enumerate}
\end{theorem}
\begin{proof}
Assuming the condition satisfied, the 2nd condition comes immediately from the Eq.~\ref{eq:def_independence}. Consequently, 3rd one holds as 
\begin{equation}
F_{X,Y}(a,b) = \mu_{X,Y}([-\infty,a]\times[-\infty,b]).
\end{equation}
The 2nd condition also implies that Fubini's theorem valid for any $h(x,y)$ integrable function and we have
\begin{equation}
\begin{aligned}
\mathbb{E}h(x,y)&=\int_{\realR^2}h(x,y)d\mu_{X,Y}\\
&=\int_\realR \int_\realR h(x,y)f_X(x)dx f_Y(y)dy.
\end{aligned}
\end{equation}
This leads to 4th condition holds.
\end{proof}


\subsection{Information and Conditioning}
For a given probability space $(\Omega, \mathfrak{R},\mathbb{P})$, $\Omega$ suppose to contained all the possible events occur, and the $\sigma$-algebra $\mathfrak{R}$ represents all the possible set to be distinguished, or measured by probability $\mathbb{P}$. The information about the event is ability to label the event with more details. This means that the more information we have, the smaller subset of $\Omega$ can be measured. Based on this idea, a $\sigma$-algebra $\mathfrak{G}\subseteq \mathfrak{R}$ stays for the limit we can measure under certain information condition.

\begin{definition}
Let $\mathfrak{G}$ be a sub-$\sigma$-algebra of $\mathfrak{R}$ in $(\Omega, \mathfrak{R},\mathbb{P})$ and $X$ is a non-negative or integrable random variable. The \textbf{conditoinal expectation} of $X$ given condition $\mathfrak{G}$, denoted as $\mathbb{E}(X|\mathfrak{G})$, is any random varialbe satisfies
\begin{enumerate}
\item Measurability: $\mathbb{E}(X|\mathfrak{G})$ is $\mathfrak{G}$-measurable;
\item Partial average:
\begin{equation}
\int_{A} \mathbb{E}(X|\mathfrak{G})(\omega)d\mathbb{P}(\omega) = \int_{A}X(\omega)d\mathbb{P}(\omega), \quad \forall A\in\mathfrak{G}.
\label{def:condition_expectation}
\end{equation}
\end{enumerate}
If $\mathfrak{G}=\sigma(W)$, a $\sigma$-algebra generated by random variable $W$, then we denoted $\expect(X|W):=\expect(X|\sigma(W))$.
\end{definition}

The requriements in the definitions preserved the existance and the uniqueness of the $\expect(X|\mathfrak{G})$. The Eq.~\ref{def:condition_expectation} defined a new measure, denoted as $\mu_X|_\mathfrak{G}$ on $(\Omega,\mathfrak{G},\mathbb{P}|_\mathfrak{G})$ where $\mathbb{P}|_\mathfrak{G}$ is a restrict of $\mathbb{P}$ to $\mathfrak{G}$. Based on the Radon-Nikodym theorem, it implies the existance of $\expect(X|\mathfrak{G})$ which equal to the Radon-Nikodym derivative $d\mu_X|_\mathfrak{G}/d\mathbb{P}|_\mathfrak{G}$. The uniqueness can be varified as follow: Assuming $Y,Z$ are two variables satisfying the Eq.~\ref{def:condition_expectation}, and $A$ is a set that $Y(a)\le Z(a),\forall a\in A$, then the integral of $Z-Y$ should be non-negative, however, 
\begin{equation*}
\int_A \left\{Z(a)-Y(a)\right\}d\mathbb{P} = 0,\quad \forall A\in\mathfrak{G},
\end{equation*}
which implies that $Z=Y$ by mean (in other term, it is called $Z=Y$ almost surely).

\begin{theorem}
Let $(\Omega,\mathfrak{R},\mathbb{P})$ be a probability space, $X$ be a integrable random variable, and $\mathfrak{G,H}$ be sub-$\sigma$-algebra.
\begin{enumerate}
\item Linearilty: Given integrable random variables $X,Y$ and $a,b\in\realR$, then
\begin{equation}
\expect(aX+bY|\mathfrak{G})=a\expect(X|\mathfrak{G})+b\expect(Y|\mathfrak{G}).
\end{equation}
\item If $X,Y$ are integrable, $XY$ is integrable as well, and $X$ is $\mathfrak{G}$-measurable, then 
\begin{equation}
\expect(XY|\mathfrak{G})=X\expect(Y|\mathfrak{G}).
\end{equation}
\item Suppose $\mathfrak{H}$ is a $\sigma$-algebra that $\mathfrak{H}\subseteq\mathfrak{G}$, then
\begin{equation}
\expect\left[(X|\mathfrak{G})|\mathfrak{H}\right]=\expect(X|\mathfrak{H}).
\end{equation}
\item If $\sigma(X)\ci\mathfrak{G}$, then
\begin{equation}
\expect(X|\mathfrak{G})=\expect X
\end{equation}
\item Jensen's inequality: If $\varphi(x)$ is a convex function, then
\begin{equation}
\expect[\varphi(X)|\mathfrak{G}]\ge\varphi\left[\expect(X|\mathfrak{G})\right].
\end{equation}
\end{enumerate}
\end{theorem}

\begin{proof}
The linearity comes from the linearity properties of Lebesgue integral. For the 2nd point, it is enough to notice that
\begin{equation*}
\int_A\mathbb{I}_{B}\expect(Y|\mathfrak{G})(\omega)d\mathbb{P}=\int_{A\cap B}Y(\omega)d\mathbb{P}=\int_A\mathbb{I}_BY(\omega)d\mathbb{P},\\
\end{equation*}
where $B\subseteq A\in\mathfrak{G}$. Any integrable $X$ can be approximated by the summation of $\mathbb{I}_B,\forall B\in \mathfrak{G}$ monotonically. It follows that the integral convergs which conclude this theorem.
For the 3rd point, it is obvious by expanding two sides for the equation by the definition Eq.\ref{def:condition_expectation}. 

To prove the 4th one, suppose $X=\mathbb{I}_B$ where $B\in\sigma(X)$, then
\begin{equation*}
\int_A X(\omega)d\mathbb{P}=\mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)=\int_A \expect Xd\mathbb{P},
\end{equation*}
which conclude this theorem.
The last point comes from the properties of a convex function $\varphi(x)$ that
\begin{equation}
\varphi(tx_1+(1-t)x_2)\le t\varphi(x_1)+(1-t)\varphi(x_2),
\end{equation}
and this definition can be extend to 
\begin{equation}
\varphi\left(\sum_{i=1}^nt_ix_i\right)\le\sum_{i=1}^nt_i\varphi(x_i),
\end{equation}
since, by induction, we assume the equation valid for $n-1$ case, and for $n$ term case, it can be expended as
\begin{equation*}
\begin{aligned}
\varphi\left(\sum_{i=1}^nt_ix_i\right)&\le t_n\varphi(x_n)+\frac{1}{1-t_n}\varphi\left(\sum_{i=1}^{n-1}\frac{t_i}{1-t_n}x_i\right),\\
&\le\sum_{i=1}^nt_i\varphi(x_i),
\end{aligned}
\end{equation*}
as the $\sum_{i=1}^{n-1}t_i/(1-t_n)=1$. On the other hand, a expectation of $X$ can be approximated by a sequence of simple function like $X_n=\sum x_n\mathbb{P}(A_{x_n})$ and $\sum\mathbb{P}(A_{x_n})=1$ by definition, where $A_{x_n}=X^{-1}[x_n,x_n+1/n]$. These two points lead to this theorem.
\end{proof}


\begin{definition}
A sequence of $\sigma$-algebra $\mathfrak{F}(t)$, ordered by a parameter $t$, is called a \textbf{Filtration} if $\mathfrak{F}(s)\subseteq\mathfrak{F}(t),\forall s\le t$. Given a sequence of random varialbes $X(t)$ indexed by $t\in[0,T]$ is called an \textbf{Adapted Stochastic Process} if $X(t)$ is $\mathfrak{F}(t)$-measurable $\forall t\in[0,T]$. A stochastic process $X(t)$ is called \textbf{Martingale} if 
\begin{equation}
\expect[X(t)|\mathfrak{F}(s)]=X(s),\quad\forall s\le t\in[0,T].
\end{equation}
Furthermore, let $f(x),g(x)$ are both Borel-measurable functions, we call $X(t)$ as a \textbf{Markov Process} if 
\begin{equation}
\expect[f(X(t))|\mathfrak{F}(s)]=g(X(s))\quad\forall s\le t\in[0,T].
\end{equation} 
\end{definition}